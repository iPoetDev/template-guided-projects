# Development Workflow

### Table of Contents

- [Features](#features)
- [Design](#design)
- [Workflows](#workflow)
- [Hosting](#hosting)
- [Deployment](#hosting)
- [Production](#production)

## Features

1. [#2 [Feature] ðŸš€ : UI | Voice Assistant Interface](https://github.com/iPoetDev/template-guided-projects/issues/2)
2. [#3 [Feature] ðŸš€ Server | Backend for Voice Assistant Services](https://github.com/iPoetDev/template-guided-projects/issues/3)
3. [#4 [Feature] ðŸš€ : Infra/Host | Containerization: Packaging App and Components](https://github.com/iPoetDev/template-guided-projects/issues/4)
4. [#5 [Feature] ðŸš€ : API | Watson Speech-to-Text > Integrate](https://github.com/iPoetDev/template-guided-projects/issues/5)
5. [#6 [Feature] ðŸš€ : API | OpenAI API](https://github.com/iPoetDev/template-guided-projects/issues/6)
6. [#7 [Feature] ðŸš€ API | Watson Text-to-Speech > Integrate](https://github.com/iPoetDev/template-guided-projects/issues/7)
7. [#8 [Feature] ðŸš€ Backend | API | Endpoints: Flask HTTP Routing (Server | Worker)](https://github.com/iPoetDev/template-guided-projects/issues/8)

## Produce

**<ins>UI</ins>**

- [ ] To type in text input to a UI interface for a Virtual Assistant chat bot
- [ ] To speak in spoken inpy to a UI interface for a Virtual Assistant chat bot
- [ ] To change and select different personal assistant voices

**<ins>Backend</ins>**

- [ ] To be able to have my spoken words transcribed from speech to text
- [ ] To interact via the front end using natural language and voice transcribed input
- [ ] To receive the responses in natural language or text
- [ ] To have the response displayed or have the choice to synthesise (to speak) the response

*<ins>API Endpoint Routing</ins>*
- [ ] To route and converts the user's speech-to-text using the speech_to_text functionality via a Speech to Text routing.
- [ ] To accept a user's message in text form with their preferred voice via defined routing for the processed message with text to speech.
- [ ] To use our previously defined helper functions to call the LLM Providers API to process this prompt via a defined routing for the processed message
- [ ] convert that response to text using Watson's Text to Speech API and then return this data back to the user via defined routing for the processed message

**<ins>Infra/Host</ins>**

- [ ] To combining (package) all the above components into a functional app
- [ ] To be able to deploy and consistently across different environments, via containers.

**<ins>API</ins>**

- [ ] To to be able to take a user's voice as input for a chat application by integrating a speech to text model
- [ ] To process transcribed queries by OpenAI's a state-of-the-art natural language processing model.
- [ ] To have a LLM NLP model in your assistant to understand and respond to a wide range of user inputs.
- [ ] To process responses from OpenAI's a state-of-the-art natural language processing model.
- [ ] To be able to take a NLP LLM output as text and convert it / synthesise into voices for a chat application by integrating a text to speech model

## Workflow

## Hosting

## Deployment

## Production
